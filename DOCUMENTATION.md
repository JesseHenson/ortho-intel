# Orthopedic Intelligence Platform Documentation

## ğŸ“‹ Table of Contents

1. [Project Overview](#project-overview)
2. [Architecture & Components](#architecture--components)
3. [Core Features](#core-features)
4. [Technical Implementation](#technical-implementation)
5. [Data Models & Progressive Disclosure](#data-models--progressive-disclosure)
6. [API & Integration](#api--integration)
7. [User Interface](#user-interface)
8. [Deployment & Infrastructure](#deployment--infrastructure)
9. [Development Guidelines](#development-guidelines)
10. [Testing & Quality Assurance](#testing--quality-assurance)
11. [Configuration & Environment](#configuration--environment)
12. [Troubleshooting](#troubleshooting)

---

## ğŸ“– Project Overview

### What is Orthopedic Intelligence?

The **Orthopedic Intelligence Platform** is a competitive intelligence solution designed specifically for medical device marketing firms. It transforms weeks of manual competitive research into AI-powered analysis that delivers actionable insights in minutes.

### Business Context

- **Target Users**: Marketing professionals serving medical device manufacturers
- **Primary Use Case**: Evidence-based competitive intelligence for strategic decision making
- **Value Proposition**: Replace manual research with AI-driven opportunity identification
- **Market Focus**: Initially spine fusion devices, expanding to full medical device spectrum

### Current Status

âœ… **MVP Deployed** - Working demo ready for marketing firm presentations  
ğŸ¯ **Phase**: MVP â†’ Production-Ready Product  
ğŸ“ˆ **Goal**: Robust, multi-use-case platform for medical device marketing firms

---

## ğŸ—ï¸ Architecture & Components

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FRONTEND LAYER                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚   Streamlit     â”‚    â”‚   React (Future)â”‚                    â”‚
â”‚  â”‚   Web App       â”‚    â”‚   Progressive   â”‚                    â”‚
â”‚  â”‚                 â”‚    â”‚   Disclosure    â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BACKEND LAYER                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚   FastAPI       â”‚    â”‚   LangGraph     â”‚                    â”‚
â”‚  â”‚   REST API      â”‚    â”‚   Pipeline      â”‚                    â”‚
â”‚  â”‚                 â”‚    â”‚   Engine        â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DATA LAYER                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚   Tavily        â”‚    â”‚   AI Models     â”‚                    â”‚
â”‚  â”‚   Search API    â”‚    â”‚   (OpenAI,      â”‚                    â”‚
â”‚  â”‚                 â”‚    â”‚   Anthropic)    â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Directory Structure

```
ortho-intel/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ backend/
â”‚   â”‚   â”œâ”€â”€ api/                 # FastAPI endpoints
â”‚   â”‚   â”œâ”€â”€ core/               # Data models and business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ data_models.py      # Core analysis models
â”‚   â”‚   â”‚   â”œâ”€â”€ opportunity_data_models.py  # Opportunity models
â”‚   â”‚   â”‚   â””â”€â”€ source_models.py    # Source citation models
â”‚   â”‚   â”œâ”€â”€ pipelines/          # LangGraph analysis pipelines
â”‚   â”‚   â”‚   â””â”€â”€ main_langgraph_opportunity.py
â”‚   â”‚   â”œâ”€â”€ utils/             # Utility functions
â”‚   â”‚   â””â”€â”€ tests/             # Backend tests
â”‚   â”œâ”€â”€ frontend/
â”‚   â”‚   â”œâ”€â”€ streamlit_app_opportunity.py    # Main Streamlit app
â”‚   â”‚   â”œâ”€â”€ components/        # Progressive disclosure components
â”‚   â”‚   â”œâ”€â”€ auth/             # Authentication (future)
â”‚   â”‚   â””â”€â”€ tests/            # Frontend tests
â”‚   â””â”€â”€ frontend-react/       # React frontend (future)
â”œâ”€â”€ docs/                     # Documentation
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ package.json             # Node.js dependencies
â”œâ”€â”€ railway.json             # Railway deployment config
â”œâ”€â”€ DEPLOYMENT.md            # Deployment instructions
â””â”€â”€ streamlit_app_opportunity.py  # Main app launcher
```

---

## ğŸ¯ Core Features

### 1. AI-Powered Competitive Analysis

**LangGraph Pipeline Processing:**
- **Category Detection**: Automatically identifies device category (spine fusion, joint replacement, etc.)
- **Intelligent Research**: Multi-source data gathering from credible medical sources
- **Gap Analysis**: Identifies clinical, product, brand, and market gaps
- **Opportunity Generation**: Transforms gaps into actionable strategic opportunities

**Supported Device Categories:**
- Spine Fusion Devices (primary focus)
- Joint Replacement Systems
- Trauma Fixation Products
- Sports Medicine Equipment
- Neurosurgery Devices
- Orthobiologics

### 2. Progressive Disclosure UI

**Three-Tier Information Architecture:**
- **Summary Level**: Essential opportunity overview for quick scanning
- **Detail Level**: Implementation guidance and strategic context
- **Full Analysis**: Complete analysis with methodology and source citations

**Real-Time Source Credibility Assessment:**
- ğŸŸ¢ **High Credibility**: PubMed, FDA, Reuters, Bloomberg, WSJ, Nature, NEJM
- ğŸŸ¡ **Medium Credibility**: Forbes, CNN, BBC, Medscape, MedTechDive
- ğŸ”´ **Low Credibility**: Unverified sources, limited attribution
- âšª **Unknown**: Analysis-based insights without external sources

### 3. Strategic Opportunity Identification

**Opportunity Categories:**
- **Product Innovation**: Feature gaps, technology limitations, R&D opportunities
- **Brand Strategy**: Positioning weaknesses, messaging gaps, reputation leverage
- **Market Positioning**: Segment opportunities, geographic expansion, competitive advantage
- **Pricing Strategy**: Pricing gaps, value proposition optimization, reimbursement strategies

**Opportunity Scoring & Prioritization:**
- **Opportunity Score**: 1-10 rating based on business impact potential
- **Implementation Difficulty**: Easy/Medium/Hard assessment
- **Time to Market**: Estimated timeline for opportunity realization
- **Investment Level**: Low/Medium/High resource requirements
- **Competitive Risk**: Risk assessment for competitive response

### 4. Executive-Ready Reporting

**Comprehensive Analysis Output:**
- **Executive Summary**: Key insights and immediate actions
- **Opportunity Matrix**: Impact vs. difficulty visualization
- **Competitive Landscape**: Detailed competitor profiles
- **Strategic Recommendations**: Actionable next steps
- **Source Attribution**: Complete citation and credibility tracking

---

## ğŸ”§ Technical Implementation

### LangGraph Processing Pipeline

The core analysis engine uses LangGraph for sophisticated multi-node processing:

```python
# Pipeline Nodes:
1. detect_category      # Device category identification
2. initialize          # Research query generation
3. research_competitor  # Multi-source data gathering
4. analyze_competitive_gaps  # Gap identification
5. generate_opportunities    # Opportunity transformation
6. categorize_opportunities  # Opportunity classification
7. synthesize_opportunity_report  # Executive summary generation
```

**Key Processing Features:**
- **Parallel Search Execution**: Multiple search queries run simultaneously
- **Source Metadata Capture**: Detailed source analysis and credibility scoring
- **Error Handling**: Graceful degradation with partial results
- **Progress Tracking**: Real-time analysis status updates

### Data Models Architecture

**Core Model Hierarchy:**
```python
# Progressive Disclosure Models
OpportunitySummary      # Summary-level display
    â†“ extends
OpportunityDetail       # Detailed information
    â†“ extends
OpportunityFull        # Complete analysis with sources

# Supporting Models
StrategicOpportunity   # Core opportunity data
CategoryOpportunity    # Category-specific opportunities
CompetitorProfile      # Competitor analysis
ExecutiveSummary      # Executive reporting
```

**Source Citation Integration:**
- **SourceCitation**: Individual source metadata
- **SourceCollection**: Aggregated source analysis
- **SourceAnalysisResult**: Comprehensive source quality assessment
- **TavilySourceMetadata**: Enhanced Tavily search result processing

### AI Integration

**Multiple AI Provider Support:**
- **OpenAI**: Primary analysis engine (GPT-4)
- **Anthropic**: Alternative analysis provider (Claude)
- **Perplexity**: Research-backed analysis enhancement
- **Tavily**: Professional search API integration

**AI Processing Features:**
- **Prompt Engineering**: Specialized prompts for medical device analysis
- **Response Validation**: Pydantic model validation for all AI outputs
- **Fallback Mechanisms**: Alternative providers for reliability
- **Cost Optimization**: Efficient token usage and response caching

---

## ğŸ“Š Data Models & Progressive Disclosure

### Progressive Disclosure Pattern

The application implements a sophisticated progressive disclosure system:

**Level 1: Summary (OpportunitySummary)**
- Essential opportunity information
- Quick assessment metrics
- Visual credibility indicators
- Computed quality scores

**Level 2: Detail (OpportunityDetail)**
- Comprehensive opportunity description
- Implementation guidance
- Source highlights and evidence summary
- Strategic context and risk assessment

**Level 3: Full (OpportunityFull)**
- Complete methodology transparency
- Detailed source analysis
- Decision audit trails
- Comprehensive competitive intelligence

### Source Credibility System

**Automated Credibility Assessment:**
```python
# Credibility Scoring (1-10)
High Credibility (8-10): Academic, government, tier-1 business sources
Medium Credibility (6-7): Established media, industry publications
Low Credibility (1-5): Unverified sources, limited attribution
```

**Source Type Classification:**
- Academic Research (PubMed, journals)
- Government Sources (FDA, regulatory bodies)
- Industry Reports (specialized publications)
- Business News (financial publications)
- General Media (news organizations)

### Opportunity Categorization

**Strategic Opportunity Types:**
1. **Product Innovation**: Technology gaps, feature opportunities
2. **Brand Strategy**: Positioning improvements, messaging optimization
3. **Market Positioning**: Competitive advantage, market expansion
4. **Pricing Strategy**: Value proposition, pricing optimization
5. **Market Expansion**: Geographic growth, segment penetration
6. **Operational Efficiency**: Process improvements, cost optimization

---

## ğŸ”Œ API & Integration

### FastAPI Backend

**Core Endpoints:**
```python
# Analysis Endpoints
POST /api/analyze/opportunity      # Run opportunity analysis
GET  /api/analyze/status/{id}      # Check analysis status
GET  /api/analyze/result/{id}      # Retrieve analysis results

# Health & Status
GET  /health                       # Health check
GET  /api/info                     # System information

# Future Endpoints
GET  /api/opportunities            # List opportunities
POST /api/opportunities/{id}/export # Export opportunity analysis
```

**Request/Response Format:**
```json
{
  "competitors": ["Stryker Spine", "Medtronic Spine"],
  "focus_area": "spine_fusion",
  "analysis_type": "opportunities_first",
  "client_name": "Example Client",
  "research_enabled": true
}
```

### External API Integration

**Tavily Search API:**
- Professional search with source credibility
- Real-time competitive intelligence gathering
- Structured result processing and metadata extraction

**AI Provider APIs:**
- OpenAI GPT-4 for primary analysis
- Anthropic Claude for alternative processing
- Perplexity for research-backed insights

---

## ğŸ’» User Interface

### Streamlit Web Application

**Main Interface Components:**
1. **Configuration Sidebar**: Competitor selection, analysis parameters
2. **Analysis Dashboard**: Real-time progress tracking
3. **Progressive Disclosure Results**: Tiered opportunity display
4. **Executive Summary**: Key insights and recommendations
5. **Category Tabs**: Organized opportunity categorization
6. **Competitive Landscape**: Detailed competitor profiles

**User Experience Features:**
- **Quick Select**: Predefined competitor options
- **Custom Input**: Manual competitor entry
- **Real-time Progress**: Analysis status updates
- **Interactive Exploration**: Expandable opportunity details
- **Export Capabilities**: Professional report generation

### React Frontend (Future)

**Planned React Migration:**
- Enhanced performance and interactivity
- Advanced data visualization
- Improved mobile responsiveness
- Real-time collaboration features
- White-label customization options

---

## ğŸš€ Deployment & Infrastructure

### Current Deployment Architecture

**Production Stack:**
- **Frontend**: Streamlit app hosted on Railway/Heroku
- **Backend**: FastAPI server with LangGraph processing
- **Database**: File-based storage (future: PostgreSQL)
- **Search**: Tavily API integration
- **AI**: OpenAI, Anthropic, Perplexity APIs

**Deployment Platforms:**
- **Railway**: Backend API deployment (recommended)
- **Vercel**: Frontend static hosting (future React app)
- **Heroku**: Alternative backend hosting
- **Docker**: Containerized deployment support

### Environment Configuration

**Required Environment Variables:**
```bash
# AI Provider Keys
ANTHROPIC_API_KEY=your_anthropic_key
PERPLEXITY_API_KEY=your_perplexity_key
OPENAI_API_KEY=your_openai_key
TAVILY_API_KEY=your_tavily_key

# Application Configuration
PORT=8000
PYTHONPATH=/app/src
```

**Deployment Files:**
- `railway.json`: Railway deployment configuration
- `requirements.txt`: Python dependencies
- `Procfile`: Heroku deployment configuration
- `runtime.txt`: Python version specification

---

## ğŸ‘¨â€ğŸ’» Development Guidelines

### Setup Instructions

1. **Clone Repository:**
```bash
git clone <repository-url>
cd ortho-intel
```

2. **Create Virtual Environment:**
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows
```

3. **Install Dependencies:**
```bash
pip install -r requirements.txt
```

4. **Set Environment Variables:**
```bash
cp .env.example .env
# Edit .env with your API keys
```

5. **Run Application:**
```bash
streamlit run streamlit_app_opportunity.py
```

### Code Organization Standards

**Backend Organization:**
- `src/backend/core/`: Data models and business logic
- `src/backend/pipelines/`: LangGraph processing workflows
- `src/backend/api/`: FastAPI endpoints
- `src/backend/utils/`: Utility functions and helpers

**Frontend Organization:**
- `src/frontend/`: Streamlit application components
- `src/frontend/components/`: Reusable UI components
- `src/frontend/tests/`: Frontend testing suite

### Development Patterns

**LangGraph Command Pattern:**
```python
# Standard node return format
return Command(
    update={"key": "value"},
    goto="next_node"
)
```

**Error Handling:**
```python
try:
    result = process_data()
except Exception as e:
    # Log error, continue with partial results
    return partial_results_with_error(e)
```

**Progressive Disclosure:**
```python
# Always implement three-tier disclosure
class OpportunitySummary(ProgressiveDisclosureModel):
    # Essential fields only
    
class OpportunityDetail(OpportunitySummary):
    # Extended fields
    
class OpportunityFull(OpportunityDetail):
    # Complete analysis
```

---

## ğŸ§ª Testing & Quality Assurance

### Test Structure

**Backend Tests:**
- `src/backend/tests/`: Core business logic tests
- Model validation tests
- Pipeline integration tests
- API endpoint tests

**Frontend Tests:**
- `src/frontend/tests/`: UI component tests
- Progressive disclosure tests
- Integration tests

### Test Categories

**Unit Tests:**
- Data model validation
- Utility function testing
- Business logic verification

**Integration Tests:**
- LangGraph pipeline testing
- API endpoint validation
- Database integration tests

**End-to-End Tests:**
- Complete analysis workflow
- User interface functionality
- Cross-browser compatibility

### Quality Assurance

**Code Quality:**
- Pydantic model validation
- Type hints throughout codebase
- Comprehensive error handling
- Structured logging

**Performance:**
- Parallel processing optimization
- Efficient API usage
- Response caching strategies
- Memory usage optimization

---

## âš™ï¸ Configuration & Environment

### Application Configuration

**Model Configuration:**
```python
# AI model settings
DEFAULT_MODEL = "gpt-4o-mini"
TEMPERATURE = 0.1
MAX_TOKENS = 4000
```

**Search Configuration:**
```python
# Tavily search settings
TAVILY_MAX_RESULTS = 10
TAVILY_SEARCH_DEPTH = "advanced"
```

**Analysis Configuration:**
```python
# Pipeline settings
MAX_COMPETITORS = 10
MAX_SEARCH_ITERATIONS = 4
ANALYSIS_TIMEOUT = 300  # seconds
```

### Environment Management

**Development Environment:**
- Local development with `.env` file
- Streamlit development server
- Hot reload for code changes

**Production Environment:**
- Environment variable configuration
- Secure API key management
- Production logging and monitoring

---

## ğŸ”§ Troubleshooting

### Common Issues

**Import Errors:**
```bash
# Problem: ImportError: attempted relative import with no known parent package
# Solution: Always run from project root
streamlit run streamlit_app_opportunity.py
```

**API Key Issues:**
```bash
# Problem: API authentication failures
# Solution: Verify environment variables
echo $ANTHROPIC_API_KEY
echo $PERPLEXITY_API_KEY
```

**Model Validation Errors:**
```python
# Problem: Pydantic validation failures
# Solution: Use safe model creation patterns
try:
    opportunity = StrategicOpportunity(**data)
except ValidationError as e:
    # Handle validation errors gracefully
    logger.error(f"Validation error: {e}")
```

### Performance Issues

**Slow Analysis:**
- Check API rate limits
- Verify network connectivity
- Monitor token usage

**Memory Issues:**
- Implement response caching
- Optimize data structures
- Use streaming for large datasets

### Debugging Tools

**Logging:**
```python
import logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
```

**Development Mode:**
```bash
# Enable debug mode
export STREAMLIT_DEBUG=True
streamlit run streamlit_app_opportunity.py
```

---

## ğŸ“ Support & Resources

### Documentation Resources

- **API Documentation**: FastAPI auto-generated docs at `/docs`
- **Code Documentation**: Inline docstrings throughout codebase
- **Deployment Guide**: See `DEPLOYMENT.md`
- **Architecture Guide**: See `docs/project/CURSOR_CONTEXT.md`

### Development Resources

- **LangGraph Documentation**: [LangGraph Official Docs](https://langchain-ai.github.io/langgraph/)
- **Streamlit Documentation**: [Streamlit Docs](https://docs.streamlit.io/)
- **FastAPI Documentation**: [FastAPI Docs](https://fastapi.tiangolo.com/)
- **Pydantic Documentation**: [Pydantic Docs](https://docs.pydantic.dev/)

### Contact Information

For technical support, feature requests, or deployment assistance:
- Review existing documentation
- Check GitHub issues
- Contact development team

---

## ğŸ—ºï¸ Roadmap & Future Development

### Immediate Priorities (Current Phase)

1. **Multi-Category Support**: Expand beyond spine fusion to full medical device spectrum
2. **Enhanced Analytics**: Regulatory analysis, pricing intelligence, clinical evidence mining
3. **Professional Export**: PowerPoint, PDF, Excel report generation
4. **Bulk Analysis**: Analyze multiple competitors simultaneously

### Medium-Term Goals

1. **React Migration**: Enhanced frontend with improved performance
2. **Multi-Tenant Support**: Support for multiple marketing firms
3. **Historical Tracking**: Track competitive changes over time
4. **Team Collaboration**: Share analyses across marketing teams

### Long-Term Vision

1. **Predictive Analytics**: Forecast competitive moves and market trends
2. **White-Label Platform**: Customizable branding for marketing firms
3. **API Ecosystem**: Third-party integrations and extensions
4. **Global Expansion**: International market analysis capabilities

---

*Last Updated: December 2024*  
*Version: 1.0.0*  
*Documentation Status: Comprehensive*